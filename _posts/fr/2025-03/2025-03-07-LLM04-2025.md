---
layout: post
date: 2025-03-07
title: "OWASP Top 10 LLM04-2025 - üí•Empoisonnement des donn√©es et des mod√®lesüí•"
categories:
  - veille
  - CyberSec
  - Top10
  - OWASP
  - LLM

---

L'empoisonnement des donn√©es et des mod√®les se produit lorsque les donn√©es utilis√©es pour le pr√©-entra√Ænement,
l'ajustement ou l'int√©gration sont manipul√©es pour introduire des vuln√©rabilit√©s, des portes d√©rob√©es ou des biais.
Cette manipulation peut compromettre la s√©curit√©, les performances ou le comportement √©thique du mod√®le, entra√Ænant des
sorties nuisibles ou des capacit√©s alt√©r√©es.

#### Pourquoi est-ce important ?

L'empoisonnement des donn√©es et des mod√®les est crucial car il peut conduire √† des sorties biais√©es, des failles de
s√©curit√© ou des comportements √©thiques compromis. Les attaquants peuvent exploiter ces vuln√©rabilit√©s pour acc√©der √† des
informations sensibles, manipuler les comportements des mod√®les ou introduire des contenus toxiques .

#### Comment fonctionne une Attaque par Empoisonnement des donn√©es et des mod√®les ?

Une attaque par empoisonnement peut se produire √† diff√©rentes √©tapes du cycle de vie d'un LLM :

1. **Pr√©-entra√Ænement** : Les attaquants peuvent introduire des donn√©es malveillantes dans les jeux de donn√©es utilis√©s
   pour l'entra√Ænement initial des mod√®les.
2. **Ajustement** : Les mod√®les peuvent √™tre manipul√©s lors de l'ajustement pour des t√¢ches sp√©cifiques.
3. **Int√©gration** : Les donn√©es textuelles converties en vecteurs num√©riques peuvent √™tre alt√©r√©es pour inclure des
   vuln√©rabilit√©s.

Ces attaques peuvent passer inaper√ßues, car les mod√®les peuvent sembler fonctionner correctement tout en produisant des
r√©sultats biais√©s ou malveillants.

#### Exemples de Faille Connue

En 2024, un mod√®le PyTorch nomm√© "baller423/goober2" permettait l'ex√©cution de code arbitraire sur la machine de la
victime16. Ce mod√®le √©tablissait un shell invers√© vers une adresse IP sp√©cifique (210.117.212.93), donnant aux
attaquants un acc√®s persistant √† la machine compromise.

- **R√©f√©rence
  ** : [Backdooring HugginFace](https://www.bleepingcomputer.com/news/security/malicious-ai-models-on-hugging-face-backdoor-users-machines/)

#### Comment se prot√©ger ?

Pour se prot√©ger contre l'empoisonnement des donn√©es et des mod√®les, il est essentiel de :

1. **Suivre les Origines des Donn√©es** : Utiliser des outils comme OWASP CycloneDX ou ML-BOM pour suivre les origines et
   les transformations des donn√©es.
2. **V√©rifier les Fournisseurs de Donn√©es** : Effectuer une v√©rification rigoureuse des fournisseurs de donn√©es et
   valider les sorties des mod√®les par rapport √† des sources de confiance.
3. **Mettre en Place un Sandboxing Strict** : Limiter l'exposition des mod√®les aux sources de donn√©es non v√©rifi√©es et
   utiliser des techniques de d√©tection d'anomalies pour filtrer les donn√©es adverses.
4. **Contr√¥les d'Infrastructure** :
	- Mettre en place des contr√¥les d'infrastructure suffisants pour emp√™cher le mod√®le d'
	  acc√©der √† des sources de donn√©es non d√©sir√©es.
	- Versionner les mod√®les
5. **Surveillance Continue** : Surveiller en permanence les sorties des mod√®les pour d√©tecter les signes
   d'empoisonnement
   ou de comportements anormaux.
6. **Tests de S√©curit√©** : Effectuer des tests de s√©curit√© r√©guliers pour identifier les vuln√©rabilit√©s potentielles
   dans
   les donn√©es et les mod√®les.

**R√©f√©rences :**

- [OWASP Top 10 LLM04:2025 Data and Model Poisoning](https://genaisecurityproject.com/llmrisk/llm042025-data-and-model-poisoning/)
- [OWASP CycloneDX](https://owasp.org/www-project-cyclonedx/)
- [Backdoor Attacks on Language Models ](https://towardsdatascience.com/backdoor-attacks-on-language-models-can-we-trust-our-models-weights-73108f9dcb1f/)
- [ML-BOM](https://cyclonedx.org/capabilities/mlbom/)
- [Hugging Face Poisonning](https://www.darkreading.com/application-security/hugging-face-ai-platform-100-malicious-code-execution-models)