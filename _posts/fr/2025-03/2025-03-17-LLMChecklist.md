---
layout: post
date: 2042-03-18
title: "LLM Applications Cybersecurity and Governance Checklist v1.1 : une approche pragmatique"
categories:
  - CyberSec
  - Top10
  - OWASP
  - LLM
---

L'OWASP a publié la checklist de gouvernance autour des applications d'AI et des LLM. Cette liste, a la _'Prévert'_, est
assez interessante. Mais une approche pragmatique avec des outils me semble intéressante a vous proposer.

🛠️ **Évaluation, Vérification et Validation des Modèles d'Intelligence Artificielle**
   - Manipulation des modèles de langage par des entrées astucieuses.

🛡️ **Risque Concurrentiel**
   - Examiner comment les concurrents investissent dans l'intelligence artificielle.
   - Évaluer l'impact des contrôles actuels sur la sécurité face aux attaques renforcées par le GenAl.
   - Mettre à jour le plan de réponse aux incidents pour inclure les attaques renforcées par le GenAl.

🔍 **Modélisation des Menaces**
   - Identifier comment les attaquants pourraient accélérer les attaques contre l'organisation.
   - Anticiper des attaques hyper-personnalisées.
   - Déterminer si l'entreprise peut détecter et neutraliser les entrées nuisibles.

📋 **Inventaire des Actifs d'Intelligence Artificielle**
   - Cataloguer les services et outils d'IA existants.
   - Inclure les composants d'IA dans la liste des matières (SBOM).
   - Cataloguer les sources de données d'IA et leur sensibilité.

📚 **Formation à la Sécurité et à la Confidentialité de l'IA**
   - Impliquer les employés pour comprendre les initiatives d'IA.
   - Établir une culture de communication transparente sur l'utilisation de l'IA.
   - Former les utilisateurs sur les questions éthiques et juridiques.

💡 **Cas d'Utilisation Clairs**
   - Améliorer l'expérience client.
   - Augmenter l'efficacité opérationnelle.
   - Améliorer la gestion des connaissances.
   - Renforcer l'innovation.

🏛️ **Gouvernance**
   - Établir un RACI pour l'IA.
   - Documenter et attribuer les responsabilités de gouvernance de l'IA.
   - Créer une politique d'IA soutenue par des politiques établies.

⚖️ **Aspects Juridiques**
   - Examiner les risques pour la propriété intellectuelle.
   - Restreindre l'utilisation des outils d'IA générative pour éviter les problèmes de droits.
   - Réviser les accords de licence utilisateur final (EULA) pour l'IA.

📜 **Réglementaire**
   - Déterminer les exigences de conformité spécifiques au pays ou à l'état pour l'IA.

🔒 **Utilisation et Mise en Œuvre**
    - Modéliser les menaces et définir les limites de confiance pour les composants LLM.
    - Sécurité des données : vérifier la classification et la protection des données sensibles.

🧪 **Tests, Évaluation, Vérification et Validation**
    - Établir des tests continus tout au long du cycle de vie du modèle d'IA.
    - Fournir des métriques exécutives régulières sur la fonctionnalité, la sécurité et la robustesse du modèle d'IA.

🗺️ **Cartes de Modèle et de Risque**
    - Utiliser des cartes de modèle pour documenter les capacités et les contraintes des systèmes d'IA.
    - Mettre en œuvre des cartes de risque pour évaluer et documenter les risques associés aux applications de modèles de langage.

🔄 **Optimisation du Modèle**
    - Créer des boucles de rétroaction pour améliorer continuellement la performance et la sécurité du système.
    - Mettre en place des mécanismes de contrôle qualité pour vérifier la pertinence et l'exactitude des données récupérées.

🛡️ **Red Teaming**
    - Intégrer des tests de red teaming pour valider l'absence de vulnérabilités dans les modèles d'IA.
    - Utiliser les systèmes d'IA pour simuler des scénarios d'attaque complexes et renforcer les défenses de l'organisation.

Ces éléments visent à aider les organisations à comprendre les risques et les avantages de l'utilisation des LLM, tout
en développant une liste complète des domaines et tâches critiques nécessaires pour défendre et protéger l'organisation
lors de la mise en œuvre d'une stratégie LLM.
