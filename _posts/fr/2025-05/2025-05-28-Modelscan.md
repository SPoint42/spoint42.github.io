---
layout: post
date: 2025-05-28
title: " üõ†Ô∏èContrer les attaques par s√©rialisation de mod√®les avec Modelscan"
categories:
  - CyberSec
  - Top10
  - OWASP
  - LLM
  - Tools
---

Protect AI a lanc√© Modelscan, un projet open-source visant √† s√©curiser les mod√®les d'intelligence artificielle. Cet
outil novateur est le premier de son genre √† prendre en charge plusieurs formats de mod√®les, notamment H5, Pickle et
SavedModel, offrant une protection √©tendue √† travers des frameworks comme PyTorch, TensorFlow, Keras, Sklearn et
XGBoost.

L'objectif principal de Modelscan est de contrer les attaques par s√©rialisation de mod√®les, un risque croissant o√π du
code malveillant est int√©gr√© directement dans le mod√®le lors de sa sauvegarde et distribution. En scannant le contenu
des fichiers octet par octet, Modelscan identifie les signatures de code potentiellement dangereuses.

La force de Modelscan r√©side dans sa capacit√© √† classer les codes non s√ªrs en cat√©gories de gravit√© : CRITICAL, HIGH,
MEDIUM ou LOW, permettant aux d√©veloppeurs et aux √©quipes de s√©curit√© de prioriser et d'adresser les menaces. L'outil
fournit √©galement des codes de statut de sortie CLI clairs, facilitant l'int√©gration dans les pipelines CI/CD et l'
automatisation des processus de s√©curit√© des mod√®les.

En somme, Modelscan est un ajout crucial √† l'arsenal de cybers√©curit√© des syst√®mes d'IA. Il assure que les mod√®les
utilis√©s en production sont exempts de vuln√©rabilit√©s cach√©es, renfor√ßant ainsi la confiance et la s√©curit√© dans
l'√©cosyst√®me de l'intelligence artificielle. 

C'est un bon outil pour les d√©veloppeurs et les √©quipes de s√©curit√©  tout comme le OWASP Top10 [Machine Learning 
Security]({{home}}{% post_url 2025-03-13-OWASP-MLTOP10 %}) et [PromptFoo]({{home}}{% post_url 2025-03-19-prompfoo-1 
%}).

Pour plus de d√©tails, vous pouvez consulter la page GitHub du projet :

[Modelscan GitHub Repository](https://github.com/protectai/modelscan)