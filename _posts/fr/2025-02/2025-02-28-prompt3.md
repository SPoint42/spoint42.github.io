---
layout: post
title: "OWASP Top10 LLM01-2025 - L'Injection Indirecte ou Contextuelle de Prompt : Risques et Exemples "
date: 2025-02-28
categories: 
  - Sécurité
  - IA
  - OWASP
  - Top10 LLM
last_modified_at: 2025-02-28
---

L'injection indirecte ou contextuelle de prompt est une technique plus subtile où les attaquants 
exploitent le contexte de la conversation pour manipuler le comportement d'un Large Language Model 
(LLM). 

Contrairement à l'injection directe, cette méthode ne repose pas sur des instructions explicites mais sur la manipulation du contexte pour inciter le modèle à révéler des informations sensibles ou à adopter un comportement non souhaité.


## Comment Fonctionne l'Injection Indirecte de Prompt ?

- **Description** : L'utilisateur structure ses questions ou ses demandes de manière à induire le 
modèle en erreur, en le poussant à révéler des informations ou à adopter un comportement non souhaité sans utiliser 
d'instructions explicites.
- **Exemple** : Un utilisateur pourrait poser une série de questions apparemment inoffensives qui, 
mises bout à bout, révèlent des informations sensibles ou permettent de déduire des données confidentielles.

## Exemple de Faille Connue

- **[CVE-2024-5565](https://nvd.nist.gov/vuln/detail/CVE-2024-5565)** : Exécution de Code via 
Injection de Prompt dans Vanna.AI. Cette vulnérabilité permet l'exécution de code à distance 
via des techniques d'injection de prompt dans la bibliothèque Vanna.AI, qui offre une interface 
texte-to-SQL pour les utilisateurs. Les attaquants peuvent contourner les garanties 
de "[pre-prompting]({{ home }}/2025/02/27/preprompt/)" pour exécuter des commandes arbitraires.
    - **Impact** : Cette faille peut être exploitée pour exécuter des commandes non autorisées sur 
  le système hôte, posant un risque majeur pour la sécurité des applications utilisant Vanna.AI.
    - **Référence** : [JFrog Blog - CVE-2024-5565](https://jfrog.com/blog/prompt-injection-attack-code-execution-in-vanna-ai-cve-2024-5565/)

