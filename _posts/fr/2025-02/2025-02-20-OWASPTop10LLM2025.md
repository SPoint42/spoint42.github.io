---
layout: post
title: "OWASP Top 10 pour les Applications LLM en 2025 : La Liste"
date: 2025-02-20
categories:
  - sécurité
  - Top10 LLM
  - IA
  - OWASP
last_modified_at: 2025-03-21
---

L'OWASP a publié la version 2025 de son "Top 10 pour les Applications LLM" le 18 novembre 2024. Ce guide vise à aider
les organisations à identifier et atténuer les principaux risques de sécurité dans les applications LLM, telles que les
chatbots et les systèmes RAG. Voici un aperçu des points clés de cette nouvelle version :

### Liste des Vulnérabilités OWASP Top 10 pour LLM 2025

1. **[LLM01: Injection de Prompt]({{home}}/2025/02/26/prompt/)**
	- L’injection de prompt est une vulnérabilité qui permet à un utilisateur malveillant de modifier le comportement ou
	  la sortie d’un LLM en insérant des instructions cachées dans les entrées utilisateur. Ces instructions peuvent
	  amener le modèle à divulguer des informations sensibles, exécuter des actions non autorisées, ou même altérer son
	  fonctionnement de manière imprévue.

2. **[LLM02: Gestion de Sortie Non Sécurisée]({{home}}/2025/03/03/LLM02-2025/)**
	- La gestion de sortie non sécurisée fait référence à l’absence de contrôle ou de filtrage des données envoyées par
	  une application à l’utilisateur. Cela ne vous rappelle rien ? [XSS](), etc.), où un attaquant peut manipuler les
	  données affichées pour exécuter du code malveillant.

3. **[LLM03: Empoisonnement de la chaîne d'approvisionnement]({{home}}/2025/03/06/LLM03-2025/)**
	- L'empoisonnement de la chaîne d'approvisionnement dans le contexte des Large Language Models (LLM) fait référence
	  aux
	  vulnérabilités qui affectent l'intégrité des données d'entraînement, des modèles et des plateformes de
	  déploiement.

4. **[LLM04: Empoisonnement des données et des modèles]({{home}}/2025/03/07/LLM04-2025/)**
	- L'empoisonnement des données et des modèles se produit lorsque les données utilisées pour le pré-entraînement,
	  l'ajustement ou l'intégration sont manipulées pour introduire des vulnérabilités, des portes dérobées ou des
	  biais.
	  Cette manipulation peut compromettre la sécurité, les performances ou le comportement éthique du modèle,
	  entraînant des
	  sorties nuisibles ou des capacités altérées.

5. **[LLM05: Gestion Inappropriée des Sorties]({{home}}/2025/03/09/LLM05-2025/)**
	- La Gestion Inappropriée des Sorties concerne les défauts dans la gestion des
	  contenus générés par les LLM avant leur traitement par d'autres systèmes, exposant les applications à divers
	  risques de
	  sécurité.

6. **[LLM06: Autonomie Excessive]({{home}}/2025/03/10/LLM06-2025/)**
	- Octroyer trop d'autonomie aux systèmes basés sur les modèles de langage peut mener a de graves vulnérabilités. Ces
	  systèmes peuvent être configurés pour appeler des fonctions ou interagir avec d'autres systèmes via des
	  extensions, ce
	  qui peut entraîner des actions dommageables en réponse à des sorties inattendues ou manipulées des LLM.
	
7. **[LLM07: Fuite des Prompts Système]({{home}}/2025/03/11/LLM07-2025/)**	
   - La Fuite des Prompts Système concerne les risques liés à la fuite d'informations sensibles contenues dans les
     prompts
     système utilisés pour guider les modèles de langage. Ces prompts peuvent révéler divers secrets tels que des clés
     API,
     des chaînes de connexion ou des structures de rôles et permissions.

8. **[LLM08: Faiblesses des Vecteurs et des Embeddings]({{home}}/2025/03/13/LLM08-2025/)**
	- Les Faiblesses des Vecteurs et des Embeddings sont liés à l'utilisation de la Génération Augmentée par Recherche (
	  RAG)
	  avec les modèles de langage à grande échelle (LLM). Les faiblesses dans la génération, le stockage ou la
	  récupération des vecteurs et des embeddings peuvent être exploitées
	  pour injecter du contenu nuisible, manipuler les sorties du modèle ou accéder à des informations sensibles.

9. **[LLM09: Désinformation]({{home}}/2025/03/14/LLM09-2025/)**
	- Les modèles de langage à grande échelle (LLMs) ont révolutionné de nombreux secteurs grâce à leur capacité à
	  générer du
	  contenu automatisé et à interagir avec les utilisateurs. Cependant, ces avancées sont accompagnées de défis
	  importants,
	  notamment la propagation de la Désinformation.

10. **[LLM10: Consommation Excessive]({{home}}/2025/03/17/LLM10-2025/)**
    - La Consommation Excessive (Unbounded Consumption) est une vulnérabilité critique des modèles de langage (LLM), où des
      utilisateurs peuvent effectuer des inférences excessives et incontrôlées. Cela entraîne des risques tels que la
      dégradation du service, des pertes économiques, le vol de propriété intellectuelle et une exploitation abusive des
      ressources informatiques, particulièrement dans les environnements cloud.

Pour découvrir les nouveautés par rapport à la version 2024, consultez l'article
dédié : [Nouveautés de l'OWASP Top 10 pour LLM 2025](/2025/02/21/OWASPTop10LLMNouveautes/)